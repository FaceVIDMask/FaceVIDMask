{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mask and Social Distancing Detection ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom scipy.spatial import distance\nfrom matplotlib import pyplot as plt\nfrom keras.models import load_model\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:33.238695Z","iopub.execute_input":"2022-03-12T14:58:33.239400Z","iopub.status.idle":"2022-03-12T14:58:36.101590Z","shell.execute_reply.started":"2022-03-12T14:58:33.239217Z","shell.execute_reply":"2022-03-12T14:58:36.100356Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../working\"))\n\n\n# Any results you write to the current directory are saved as output.","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:36.103061Z","iopub.execute_input":"2022-03-12T14:58:36.103332Z","iopub.status.idle":"2022-03-12T14:58:36.111731Z","shell.execute_reply.started":"2022-03-12T14:58:36.103278Z","shell.execute_reply":"2022-03-12T14:58:36.110608Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**LOADING THE HAAR CASACADE CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"#loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('../input/haarcascades/haarcascade_frontalface_default.xml')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:36.113663Z","iopub.execute_input":"2022-03-12T14:58:36.113944Z","iopub.status.idle":"2022-03-12T14:58:36.151361Z","shell.execute_reply.started":"2022-03-12T14:58:36.113911Z","shell.execute_reply":"2022-03-12T14:58:36.150588Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**TESTING HAAR CASCADE ON A SAMPLE IMAGE**\n","metadata":{}},{"cell_type":"code","source":"#trying it out on a sample image\nimg = cv2.imread('../input/face-mask-detection/images/maksssksksss244.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\n#returns a list of (x,y,w,h) tuples\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4) \n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n\n#plotting\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\n\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:51.479521Z","iopub.execute_input":"2022-03-12T14:58:51.479841Z","iopub.status.idle":"2022-03-12T14:58:52.148820Z","shell.execute_reply.started":"2022-03-12T14:58:51.479805Z","shell.execute_reply":"2022-03-12T14:58:52.147792Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# For Social Distancing\n","metadata":{}},{"cell_type":"code","source":"MIN_DISTANCE = 130","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:55.819569Z","iopub.execute_input":"2022-03-12T14:58:55.820382Z","iopub.status.idle":"2022-03-12T14:58:55.824959Z","shell.execute_reply.started":"2022-03-12T14:58:55.820248Z","shell.execute_reply":"2022-03-12T14:58:55.824024Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if len(faces)>=2:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        if label[i]==1:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),1)\n        else:\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"No. of faces detected is less than 2\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:58:58.384911Z","iopub.execute_input":"2022-03-12T14:58:58.385593Z","iopub.status.idle":"2022-03-12T14:58:58.884151Z","shell.execute_reply.started":"2022-03-12T14:58:58.385554Z","shell.execute_reply":"2022-03-12T14:58:58.883055Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Here the Red box shows violation of social distancing.","metadata":{}},{"cell_type":"markdown","source":"# **Using VGG19 for mask detection**\n","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:02.813266Z","iopub.execute_input":"2022-03-12T14:59:02.813654Z","iopub.status.idle":"2022-03-12T14:59:02.820966Z","shell.execute_reply.started":"2022-03-12T14:59:02.813617Z","shell.execute_reply":"2022-03-12T14:59:02.819814Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Load train and test set\ntrain_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\ntest_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\nval_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:04.776164Z","iopub.execute_input":"2022-03-12T14:59:04.776911Z","iopub.status.idle":"2022-03-12T14:59:04.783219Z","shell.execute_reply.started":"2022-03-12T14:59:04.776871Z","shell.execute_reply":"2022-03-12T14:59:04.782077Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\n\ntrain_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\ntrain_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\nval_datagen = ImageDataGenerator(rescale=1.0/255)\nval_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/255)\ntest_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:06.842868Z","iopub.execute_input":"2022-03-12T14:59:06.843790Z","iopub.status.idle":"2022-03-12T14:59:12.060220Z","shell.execute_reply.started":"2022-03-12T14:59:06.843749Z","shell.execute_reply":"2022-03-12T14:59:12.059524Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Building VGG19 transfer learning model.","metadata":{}},{"cell_type":"code","source":"vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(vgg19)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='sigmoid'))\nmodel.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T14:59:15.343027Z","iopub.execute_input":"2022-03-12T14:59:15.344376Z","iopub.status.idle":"2022-03-12T14:59:16.201348Z","shell.execute_reply.started":"2022-03-12T14:59:15.344327Z","shell.execute_reply":"2022-03-12T14:59:16.200356Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras;    \nfrom tensorflow.keras import metrics;\nmodel.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['acc', keras.metrics.Precision(), keras.metrics.Recall()])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:20.647761Z","iopub.execute_input":"2022-03-12T14:59:20.648101Z","iopub.status.idle":"2022-03-12T14:59:20.676741Z","shell.execute_reply.started":"2022-03-12T14:59:20.648069Z","shell.execute_reply":"2022-03-12T14:59:20.675495Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=len(train_generator)//32,\n                              epochs=20,validation_data=val_generator,\n                              validation_steps=len(val_generator)//32)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T14:59:25.768615Z","iopub.execute_input":"2022-03-12T14:59:25.769415Z","iopub.status.idle":"2022-03-12T15:12:41.964010Z","shell.execute_reply.started":"2022-03-12T14:59:25.769370Z","shell.execute_reply":"2022-03-12T15:12:41.962410Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc, test_precision, test_recall = model.evaluate(test_generator, steps=7)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:13:33.405088Z","iopub.execute_input":"2022-03-12T15:13:33.405573Z","iopub.status.idle":"2022-03-12T15:14:00.118343Z","shell.execute_reply.started":"2022-03-12T15:13:33.405531Z","shell.execute_reply":"2022-03-12T15:14:00.117333Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Testing the model on the test data","metadata":{}},{"cell_type":"code","source":"img = cv2.imread('../input/face-mask-12k-images-dataset/Face Mask Dataset/Test/WithMask/1565.png')\nplt.imshow(img)\nimg = cv2.resize(img, (128,128)) \nimg = np.reshape(img, [1,128,128,3])/255.0\n\npred_prob = model.predict(img)\n\npred_prob","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:35.725734Z","iopub.execute_input":"2022-03-12T15:14:35.726117Z","iopub.status.idle":"2022-03-12T15:14:36.452138Z","shell.execute_reply.started":"2022-03-12T15:14:35.726084Z","shell.execute_reply":"2022-03-12T15:14:36.451028Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"The model is able to classify if the person is wearing a mask or not.","metadata":{}},{"cell_type":"markdown","source":"### Save the model.","metadata":{}},{"cell_type":"code","source":"model.save('masknet.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:39.655056Z","iopub.execute_input":"2022-03-12T15:14:39.655720Z","iopub.status.idle":"2022-03-12T15:14:40.089528Z","shell.execute_reply.started":"2022-03-12T15:14:39.655662Z","shell.execute_reply":"2022-03-12T15:14:40.088634Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# **Integrating with haar cascade**","metadata":{}},{"cell_type":"code","source":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)}","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:42.343395Z","iopub.execute_input":"2022-03-12T15:14:42.343729Z","iopub.status.idle":"2022-03-12T15:14:42.350385Z","shell.execute_reply.started":"2022-03-12T15:14:42.343696Z","shell.execute_reply":"2022-03-12T15:14:42.348519Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def mask_social(img):\n    \n    faces = face_model.detectMultiScale(img, scaleFactor=1.1, minNeighbors=4)\n    \n    if len(faces)>=2:\n        label = [0 for i in range(len(faces))]\n    \n        for i in range(len(faces)-1):\n            for j in range(i+1, len(faces)):\n                dist = distance.euclidean(faces[i][:2],faces[j][:2])\n                \n                if dist<MIN_DISTANCE:\n                    label[i] = 1\n                    label[j] = 1\n                \n        new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    \n        for i in range(len(faces)):\n            (x,y,w,h) = faces[i]\n        \n            crop = new_img[y:y+h,x:x+w]\n            crop = cv2.resize(crop,(128,128))\n            crop = np.reshape(crop,[1,128,128,3])/255.0\n        \n            mask_result = model.predict(crop)\n        \n            cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n            cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n        \n        plt.figure(figsize=(10,10))\n        plt.imshow(new_img)\n            \n    else:\n        print(\"No. of faces detected is less than 2 so social distancing detection isn't possible\")\n    \n        new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n        \n        for i in range(len(faces)):\n            (x,y,w,h) = faces[i]\n    \n            crop = new_img[y:y+h,x:x+w]\n            crop = cv2.resize(crop,(128,128))\n            crop = np.reshape(crop,[1,128,128,3])/255.0\n\n            mask_result = model.predict(crop)\n\n            cv2.putText(new_img,mask_label[mask_result.argmax()], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n            cv2.rectangle(new_img, (x,y), (x+w,y+h), 1)\n    \n        plt.figure(figsize=(10,10))\n        plt.imshow(new_img)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:45.092388Z","iopub.execute_input":"2022-03-12T15:14:45.093755Z","iopub.status.idle":"2022-03-12T15:14:45.114483Z","shell.execute_reply.started":"2022-03-12T15:14:45.093670Z","shell.execute_reply":"2022-03-12T15:14:45.112924Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"img1 = cv2.imread('../input/face-mask-detection/images/maksssksksss244.png')\nmask_social(img1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:48.722341Z","iopub.execute_input":"2022-03-12T15:14:48.722993Z","iopub.status.idle":"2022-03-12T15:14:49.840985Z","shell.execute_reply.started":"2022-03-12T15:14:48.722932Z","shell.execute_reply":"2022-03-12T15:14:49.839240Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"img2 = cv2.imread('../input/face-mask-detection/images/maksssksksss10.png')\nmask_social(img2)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:52.761073Z","iopub.execute_input":"2022-03-12T15:14:52.761406Z","iopub.status.idle":"2022-03-12T15:14:53.815581Z","shell.execute_reply.started":"2022-03-12T15:14:52.761374Z","shell.execute_reply":"2022-03-12T15:14:53.814482Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# **FACE RECOGNITION**","metadata":{}},{"cell_type":"code","source":"# extract a single face from a given photograph\n\ndef extract_face(filename, required_size=(160, 160)):\n    # load image from file\n    image = Image.open(filename)\n    \n    # convert to RGB, if needed\n    image = image.convert('RGB')\n    \n    # convert to array\n    pixels = np.asarray(image)\n    \n    # resize pixels to the model size\n    image = Image.fromarray(pixels)\n    image = image.resize(required_size)\n    face_array = np.asarray(image)\n    \n    return face_array","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:56.813621Z","iopub.execute_input":"2022-03-12T15:14:56.814521Z","iopub.status.idle":"2022-03-12T15:14:56.822261Z","shell.execute_reply.started":"2022-03-12T15:14:56.814470Z","shell.execute_reply":"2022-03-12T15:14:56.821351Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def load_face(dir):\n    faces = list()\n    paths = list()\n    \n    # enumerate files\n    for filename in os.listdir(dir):\n        path = dir + filename\n        face = extract_face(path)\n        faces.append(face)\n        paths.append(path)\n    \n    return faces, paths\n\ndef load_dataset(dir):\n    # list for faces and labels\n    X, y, paths, t_paths = list(), list(), list(), list()\n    \n    for subdir in os.listdir(dir):\n        path = dir + subdir + '/'\n        faces, paths = load_face(path)\n        t_paths = t_paths + paths\n        labels = [subdir for i in range(len(faces))]\n        X.extend(faces)\n        y.extend(labels)\n        \n    return np.asarray(X), np.asarray(y), t_paths","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:14:59.419168Z","iopub.execute_input":"2022-03-12T15:14:59.420270Z","iopub.status.idle":"2022-03-12T15:14:59.432543Z","shell.execute_reply.started":"2022-03-12T15:14:59.420186Z","shell.execute_reply":"2022-03-12T15:14:59.431201Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**LOAD AND  TRAIN FOR FACE RECOGNITION**","metadata":{}},{"cell_type":"code","source":"# load train dataset\n\ntrainX, trainy, train_paths = load_dataset('../input/fyprmfrd/RMFRD/AFDB_face_datset/')\nprint(trainX.shape, trainy.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:15:01.785412Z","iopub.execute_input":"2022-03-12T15:15:01.785788Z","iopub.status.idle":"2022-03-12T15:15:12.103589Z","shell.execute_reply.started":"2022-03-12T15:15:01.785751Z","shell.execute_reply":"2022-03-12T15:15:12.102453Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# load test dataset\n\ntestX, testy, test_paths = load_dataset('../input/fyprmfrd/RMFRD/AFDB_masked_face_dataset/')\nprint(testX.shape, testy.shape, len(test_paths))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:16:19.454576Z","iopub.execute_input":"2022-03-12T15:16:19.454941Z","iopub.status.idle":"2022-03-12T15:16:23.605056Z","shell.execute_reply.started":"2022-03-12T15:16:19.454908Z","shell.execute_reply":"2022-03-12T15:16:23.603907Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**Compress and Save Train and Test Dataset**\n After face extraction process, train and dataset occupied memory and there was a memory error. The reason of this process is to deal with this issue .","metadata":{}},{"cell_type":"code","source":"# save and compress the dataset for further use\nnp.savez_compressed('new_modified_masked_face.npz', trainX, trainy, testX, testy)\nprint('Done with Compression')\ndel trainX, trainy, testX, testy","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:17:26.821988Z","iopub.execute_input":"2022-03-12T15:17:26.822361Z","iopub.status.idle":"2022-03-12T15:17:47.680944Z","shell.execute_reply.started":"2022-03-12T15:17:26.822321Z","shell.execute_reply":"2022-03-12T15:17:47.679850Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data = np.load('/kaggle/working/new_modified_masked_face.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\ndel data","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:18:45.077536Z","iopub.execute_input":"2022-03-12T15:18:45.078838Z","iopub.status.idle":"2022-03-12T15:18:49.437890Z","shell.execute_reply.started":"2022-03-12T15:18:45.078769Z","shell.execute_reply":"2022-03-12T15:18:49.436265Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainx, valid = train_test_split(trainX, test_size=0.4, random_state=42, shuffle=True)\ndel trainX\nprint('Split Training Data')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:18:52.489358Z","iopub.execute_input":"2022-03-12T15:18:52.489889Z","iopub.status.idle":"2022-03-12T15:18:52.828985Z","shell.execute_reply.started":"2022-03-12T15:18:52.489832Z","shell.execute_reply":"2022-03-12T15:18:52.827625Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"number of image in train dataset : %s\" %(len(trainx)))\n\nprint(\"number of image in train dataset : %s\" %(len(valid)))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:18:54.917999Z","iopub.execute_input":"2022-03-12T15:18:54.918354Z","iopub.status.idle":"2022-03-12T15:18:54.924367Z","shell.execute_reply.started":"2022-03-12T15:18:54.918320Z","shell.execute_reply":"2022-03-12T15:18:54.923376Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"y_train, y_valid = train_test_split(trainy, test_size=0.4, random_state=42, shuffle=True)\ndel trainy\nprint('Split Training Data')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:18:56.959243Z","iopub.execute_input":"2022-03-12T15:18:56.960061Z","iopub.status.idle":"2022-03-12T15:18:56.968418Z","shell.execute_reply.started":"2022-03-12T15:18:56.960015Z","shell.execute_reply":"2022-03-12T15:18:56.967518Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(\"number of image in train dataset : %s\" %(len(y_train)))\n\nprint(\"number of image in train dataset : %s\" %(len(y_valid)))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:18:59.074533Z","iopub.execute_input":"2022-03-12T15:18:59.074824Z","iopub.status.idle":"2022-03-12T15:18:59.080740Z","shell.execute_reply.started":"2022-03-12T15:18:59.074793Z","shell.execute_reply":"2022-03-12T15:18:59.079575Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# save and compress the dataset for further use\nnp.savez_compressed('modified_extracted_masked_unmasked.npz', trainx, y_train, valid, y_valid,testX, testy)\ndel trainx, y_train, valid, y_valid, testX, testy\nprint('Done Compressing')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:19:00.975153Z","iopub.execute_input":"2022-03-12T15:19:00.975496Z","iopub.status.idle":"2022-03-12T15:19:21.692979Z","shell.execute_reply.started":"2022-03-12T15:19:00.975463Z","shell.execute_reply":"2022-03-12T15:19:21.691682Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"data = np.load('/kaggle/working/modified_extracted_masked_unmasked.npz')\nprint(data.files)\ntrainx, y_train, valid, y_valid,testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\nprint('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)\ndel data","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:19:48.171144Z","iopub.execute_input":"2022-03-12T15:19:48.171462Z","iopub.status.idle":"2022-03-12T15:19:52.436898Z","shell.execute_reply.started":"2022-03-12T15:19:48.171430Z","shell.execute_reply":"2022-03-12T15:19:52.435325Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**FACE EMBEDDINGS WITH FACENET**\n","metadata":{}},{"cell_type":"code","source":"facenet_model = load_model('/kaggle/input/facenet/keras-facenet/model/facenet_keras.h5')\nprint('Loaded Model')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:19:58.245003Z","iopub.execute_input":"2022-03-12T15:19:58.245324Z","iopub.status.idle":"2022-03-12T15:20:03.055494Z","shell.execute_reply.started":"2022-03-12T15:19:58.245267Z","shell.execute_reply":"2022-03-12T15:20:03.054538Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:20:05.005311Z","iopub.execute_input":"2022-03-12T15:20:05.005640Z","iopub.status.idle":"2022-03-12T15:20:05.015538Z","shell.execute_reply.started":"2022-03-12T15:20:05.005606Z","shell.execute_reply":"2022-03-12T15:20:05.014045Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def get_embedding(model, face):\n    # scale pixel values\n    face = face.astype('float32')\n    \n    # standardization\n    mean, std = face.mean(), face.std()\n    face = (face-mean)/std\n    \n    # transfer face into one sample (3 dimension to 4 dimension)\n    sample = np.expand_dims(face, axis=0)\n    \n    # make prediction to get embedding\n    yhat = model.predict(sample)\n    \n    return yhat[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:20:08.592757Z","iopub.execute_input":"2022-03-12T15:20:08.593768Z","iopub.status.idle":"2022-03-12T15:20:08.601066Z","shell.execute_reply.started":"2022-03-12T15:20:08.593719Z","shell.execute_reply":"2022-03-12T15:20:08.599711Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"**CONVERT EACH FACE IN THE TRAINSET INTO EMBEDDING**\n","metadata":{}},{"cell_type":"code","source":"emdTrainX = list()\n\nfor face in trainx:\n    emd = get_embedding(facenet_model, face)\n    emdTrainX.append(emd)\n    \nemdTrainX = np.asarray(emdTrainX)\nprint(emdTrainX.shape)\n\nembValid = list()\n\nfor face in valid:\n    emd = get_embedding(facenet_model,face)\n    embValid.append(emd)\n    \nembValid = np.asarray(embValid)\nprint(embValid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:20:19.294025Z","iopub.execute_input":"2022-03-12T15:20:19.295005Z","iopub.status.idle":"2022-03-12T15:31:51.462820Z","shell.execute_reply.started":"2022-03-12T15:20:19.294942Z","shell.execute_reply":"2022-03-12T15:31:51.461427Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"emdTestX = list()\n\nfor face in testX:\n    emd = get_embedding(facenet_model, face)\n    emdTestX.append(emd)\n    \nemdTestX = np.asarray(emdTestX)\nprint(emdTestX.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:33:28.686964Z","iopub.execute_input":"2022-03-12T15:33:28.687382Z","iopub.status.idle":"2022-03-12T15:36:58.296305Z","shell.execute_reply.started":"2022-03-12T15:33:28.687342Z","shell.execute_reply":"2022-03-12T15:36:58.295071Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**COMPRESSS AND SAVE TRAIN AND TEST EMBEDDINGS**\n","metadata":{}},{"cell_type":"code","source":"# save arrays to one file in compressed format\nnp.savez_compressed('embeddings_masked.npz', emdTrainX, y_train, embValid, y_valid, emdTestX, testy)\ndel emdTrainX, y_train, embValid, y_valid, emdTestX, testy\nprint('Here')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:10.618126Z","iopub.execute_input":"2022-03-12T15:37:10.618502Z","iopub.status.idle":"2022-03-12T15:37:10.818007Z","shell.execute_reply.started":"2022-03-12T15:37:10.618466Z","shell.execute_reply":"2022-03-12T15:37:10.816918Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"data = np.load('/kaggle/working/embeddings_masked.npz')\nprint(data.files)\nemdTrainX, y_train, embValid, y_valid, emdTestX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:14.397584Z","iopub.execute_input":"2022-03-12T15:37:14.398232Z","iopub.status.idle":"2022-03-12T15:37:14.436714Z","shell.execute_reply.started":"2022-03-12T15:37:14.398193Z","shell.execute_reply":"2022-03-12T15:37:14.435984Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print('Loaded: ', emdTrainX.shape, y_train.shape, embValid.shape, y_valid.shape, emdTestX.shape, testy.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:17.841488Z","iopub.execute_input":"2022-03-12T15:37:17.842458Z","iopub.status.idle":"2022-03-12T15:37:17.849278Z","shell.execute_reply.started":"2022-03-12T15:37:17.842406Z","shell.execute_reply":"2022-03-12T15:37:17.848548Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"**LABELLED ENCODING**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\nimport pickle\n\nprint(\"Dataset: train=%d,validation = %d, test=%d\" % (emdTrainX.shape[0],embValid.shape[0] ,emdTestX.shape[0]))\n\n# normalize input vectors\nin_encoder = Normalizer(norm='l2')\nemdTrainX_norm = in_encoder.transform(emdTrainX)\nembValid_norm = in_encoder.transform(embValid)\nemdTestX_norm = in_encoder.transform(emdTestX)\n\n# label encode targets\nout_encoder = LabelEncoder()\nencoder_arr = np.append (y_train, 'wangnan')\nout_encoder.fit(encoder_arr)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:21.105942Z","iopub.execute_input":"2022-03-12T15:37:21.106695Z","iopub.status.idle":"2022-03-12T15:37:21.155743Z","shell.execute_reply.started":"2022-03-12T15:37:21.106613Z","shell.execute_reply":"2022-03-12T15:37:21.154585Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"**ENCODING TRAINY AND TESTY WITH FITTED ENCODER**\n\n","metadata":{}},{"cell_type":"code","source":"trainy_enc = out_encoder.transform(y_train)\ny_valid_enc = out_encoder.transform(y_valid)\ntesty_enc = out_encoder.transform(testy)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:31.031193Z","iopub.execute_input":"2022-03-12T15:37:31.031564Z","iopub.status.idle":"2022-03-12T15:37:31.045924Z","shell.execute_reply.started":"2022-03-12T15:37:31.031532Z","shell.execute_reply":"2022-03-12T15:37:31.044819Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"**Face Classification with SVC**","metadata":{}},{"cell_type":"code","source":"model = SVC(kernel='linear', probability=True)\nmodel.fit(emdTrainX_norm, trainy_enc)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:37:33.302137Z","iopub.execute_input":"2022-03-12T15:37:33.303338Z","iopub.status.idle":"2022-03-12T15:37:47.502411Z","shell.execute_reply.started":"2022-03-12T15:37:33.303257Z","shell.execute_reply":"2022-03-12T15:37:47.501235Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# predict\nyhat_valid = model.predict(embValid_norm)\nyhat_test = model.predict(emdTestX_norm)\n\n# score\nscore_valid = accuracy_score(y_valid_enc, yhat_valid)\nscore_test = accuracy_score(testy_enc, yhat_test)\n\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_valid*100, score_test*100))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:38:04.893466Z","iopub.execute_input":"2022-03-12T15:38:04.893804Z","iopub.status.idle":"2022-03-12T15:38:22.060636Z","shell.execute_reply.started":"2022-03-12T15:38:04.893767Z","shell.execute_reply":"2022-03-12T15:38:22.059346Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#Save the model\nfilename = 'linear.sav'\npickle.dump(model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:39:14.857373Z","iopub.execute_input":"2022-03-12T15:39:14.857711Z","iopub.status.idle":"2022-03-12T15:39:14.912630Z","shell.execute_reply.started":"2022-03-12T15:39:14.857672Z","shell.execute_reply":"2022-03-12T15:39:14.911398Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"loaded_model = pickle.load(open('linear.sav', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:39:16.873341Z","iopub.execute_input":"2022-03-12T15:39:16.874350Z","iopub.status.idle":"2022-03-12T15:39:16.893238Z","shell.execute_reply.started":"2022-03-12T15:39:16.874275Z","shell.execute_reply":"2022-03-12T15:39:16.892473Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"**TESTING FACE RECOGNITION**","metadata":{}},{"cell_type":"code","source":"from random import choice\n\nfor i in range(50):\n    \n    # select a random face from test set\n    selection = choice([i for i in range(testX.shape[0])]) \n    random_face = testX[selection]\n    random_face_emd = emdTestX_norm[selection]\n    random_face_class = testy_enc[selection]\n    random_face_name = out_encoder.inverse_transform([random_face_class])\n    \n    # prediction for the face\n    samples = np.expand_dims(random_face_emd, axis=0)\n    yhat_class = loaded_model.predict(samples)\n    yhat_prob = loaded_model.predict_proba(samples)\n    class_index = yhat_class[0]\n    \n    if class_index <= 228:\n        # get name\n        class_probability = yhat_prob[0,class_index] * 100\n        predict_names = out_encoder.inverse_transform(yhat_class)\n        \n        if random_face_name[0] == predict_names[0]:\n            print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n            print('Expected: %s' % random_face_name[0])\n            \n            # plot face\n            plt.imshow(random_face)\n            title = '%s (%.3f)' % (predict_names[0], class_probability)\n            plt.title(title)\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:39:19.559520Z","iopub.execute_input":"2022-03-12T15:39:19.560201Z","iopub.status.idle":"2022-03-12T15:39:21.907836Z","shell.execute_reply.started":"2022-03-12T15:39:19.560159Z","shell.execute_reply":"2022-03-12T15:39:21.906648Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"#  **INTEGRATION OF MODULES**","metadata":{}},{"cell_type":"code","source":"def FaceVIDMask_social(random_face, selection, path):\n    \n    random_face_emd = emdTestX_norm[selection]\n    random_face_class = testy_enc[selection]\n    random_face_name = out_encoder.inverse_transform([random_face_class])\n    \n    # prediction for the face\n    samples = np.expand_dims(random_face_emd, axis=0)\n    yhat_class = loaded_model.predict(samples)\n    yhat_prob = loaded_model.predict_proba(samples)\n    class_index = yhat_class[0]\n    \n    class_probability = yhat_prob[0,class_index] * 100\n    predict_names = out_encoder.inverse_transform(yhat_class)\n        \n    if random_face_name[0] == predict_names[0]:\n        print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n        print('Expected: %s' % random_face_name[0])\n    \n        faces = face_model.detectMultiScale(random_face, scaleFactor=1.1, minNeighbors=1)\n    \n        if len(faces)>=2:\n            label = [0 for i in range(len(faces))]\n    \n            for i in range(len(faces)-1):\n                for j in range(i+1, len(faces)):\n                    dist = distance.euclidean(faces[i][:2],faces[j][:2])\n                \n                    if dist<MIN_DISTANCE:\n                        label[i] = 1\n                        label[j] = 1\n                \n            new_img = cv2.cvtColor(random_face, cv2.COLOR_RGB2BGR) #colored output image\n    \n            for i in range(len(faces)):\n                (x,y,w,h) = faces[i]\n        \n                crop = new_img[y:y+h,x:x+w]\n                crop = cv2.resize(crop,(128,128))\n                crop = np.reshape(crop,[1,128,128,3])/255.0\n        \n                mask_result = model.predict(crop)\n        \n                cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n                cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n        \n            plt.figure(figsize=(10,10))\n            plt.imshow(new_img)\n            \n        else:\n            print(\"No. of faces detected is less than 2 so social distancing detection isn't possible\")\n    \n            new_img = cv2.cvtColor(random_face, cv2.COLOR_RGB2BGR)\n        \n            #if len(faces) == 0:\n                #image = cv2.imread(path)\n                #img = np.resize(image, (128, 128, 3))\n                #plt.imshow(image)\n                #img = np.array(img)\n                #img = np.reshape(img,[-1,128,128,3])\n                #img = img / 255.0\n\n                #pred_prob = model.predict(img)[0]\n                #pred_class = list(pred_prob).index(max(pred_prob)) \n                \n                #if pred_class == 0:\n                    #mask_class = \"Wearing Mask\"\n                #else:\n                    #mask_class = \"Not Wearing Mask\"\n    \n                #print(mask_class)\n        \n            #else:\n            for i in range(len(faces)):\n                (x,y,w,h) = faces[i]\n    \n                crop = new_img[y:y+h,x:x+w]\n                crop = cv2.resize(crop,(128,128))\n                crop = np.reshape(crop,[1,128,128,3])/255.0\n\n                mask_result = model.predict(crop)\n\n                cv2.putText(new_img,mask_label[mask_result.argmax()], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n                cv2.rectangle(new_img, (x,y), (x+w,y+h), 1)\n    \n        plt.figure(figsize=(10,10))\n        plt.imshow(new_img)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:46:06.058620Z","iopub.execute_input":"2022-03-12T15:46:06.058992Z","iopub.status.idle":"2022-03-12T15:46:06.083993Z","shell.execute_reply.started":"2022-03-12T15:46:06.058956Z","shell.execute_reply":"2022-03-12T15:46:06.082779Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    \n    # select a random face from test set\n    selection = choice([i for i in range(testX.shape[0])]) \n    random_face = testX[selection]\n    path = test_paths[selection]\n    \n    FaceVIDMask_social(random_face, selection, path)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T15:46:31.170056Z","iopub.execute_input":"2022-03-12T15:46:31.170376Z","iopub.status.idle":"2022-03-12T15:46:31.485937Z","shell.execute_reply.started":"2022-03-12T15:46:31.170342Z","shell.execute_reply":"2022-03-12T15:46:31.485008Z"},"trusted":true},"execution_count":74,"outputs":[]}]}